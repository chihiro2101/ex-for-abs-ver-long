Hardware random number generator

uses . unpredictable random numbers were first investigated in the context of gambling , and many randomizing devices such as dice , shuffling playing cards , and roulette wheels , were first developed for such use . fairly produced random numbers are vital to electronic gambling and ways of creating them are sometimes regulated by governmental gaming commissions . random numbers are also used for non-gambling purposes , both where their use is mathematically important , such as sampling for opinion polls , and in situations where fairness is approximated by randomization , such as conscription and selecting jurors . cryptography . the major use for hardware random number generators is in the field of data encryption , for example to create random cryptographic keys and nonces needed to encrypt and sign data . they are a more secure alternative to pseudorandom number generators ( prngs ) , software programs commonly used in computers to generate '' random '' numbers . prngs use a deterministic algorithm to produce numerical sequences . although these pseudorandom sequences pass randomness tests , by knowing the algorithm and the conditions used to initialize it , called the '' seed '' , the output can be predicted . because the sequence of numbers produced by a prng is in principle predictable , data encrypted with pseudorandom numbers is potentially vulnerable to cryptanalysis . hardware random number generators produce sequences of numbers that are assumed not to be predictable , and therefore provide the greatest security when used to encrypt data . early work . one early way of producing random numbers was by a variation of the same machines used to play keno or select lottery numbers . these involved mixed , numbered ping-pong balls with blown air , perhaps combined with mechanical agitation , and used some method to withdraw balls from the mixing chamber . this method gives reasonable results in some senses , but the random numbers generated by this means are expensive . the method is inherently slow , and is unusable for most computing applications . on 29 april 1947 , rand corporation began generating random digits with an '' electronic roulette wheel '' , consisting of a random frequency pulse source of about 100,000 pulses per second gated once per second with a constant frequency pulse and fed into a five-bit binary counter . douglas aircraft built the equipment , implementing cecil hasting 's suggestion ( rand p-113 ) . for a noise source ( most likely the well known behavior of the 6d4 miniature gas thyratron tube , when placed in a magnetic field ) . twenty of the 32 possible counter values were mapped onto the 10 decimal digits and the other 12 counter values were discarded . . the results of a long run from the rand machine , filtered and tested , were converted into a table , which was published in 1955 in the book a million random digits with 100,000 normal deviates . the rand table was a significant breakthrough in delivering random numbers because such a large and carefully prepared table had never before been available . it has been a useful source for simulations , modeling , and for deriving the arbitrary constants in cryptographic algorithms to demonstrate that the constants had not been selected maliciously . the block ciphers khufu and khafre are among the applications which use the rand table . see : nothing up my sleeve numbers . physical phenomena with random properties . quantum random properties . there are two fundamental sources of practical quantum mechanics physical randomness : quantum mechanics at the atomic or sub-atomic level and thermal noise ( some of which is quantum mechanical in origin ) . quantum mechanics predicts that certain physical phenomena , such as the nuclear decay of atoms , '' each nucleus decays spontaneously , at random , in accordance with the blind workings of chance . '' q for quantum , john gribbin are fundamentally random and can not , in principle , be predicted ( for a discussion of empirical verification of quantum unpredictability , see bell test experiments ) . and , because the world exists at a temperature above absolute zero , every system has some random variation in its state ; for instance , molecules of gases composing air are constantly bouncing off each other in a random way ( see statistical mechanics . ) this randomness is a quantum phenomenon as well ( see phonon ) . because the outcome of quantum-mechanical events can not be predicted even in principle , they are the ‘ gold standard ’ for random number generation . some quantum phenomena used for random number generation include : shot noise , a quantum mechanical noise source in electronic circuits . a simple example is a lamp shining on a photodiode . due to the uncertainty principle , arriving photons create noise in the circuit . collecting the noise for use poses some problems , but this is an especially simple random noise source . however , shot noise energy is not always well distributed throughout the bandwidth of interest . gas diode and thyratron electron tubes in a crosswise magnetic field can generate substantial noise energy ( 10 volts or more into high impedance loads ) but have a very peaked energy distribution and require careful filtering to achieve flatness across a broad spectrum . . a nuclear decay radiation source , detected by a geiger counter attached to a pc . photons travelling through a beam splitter . the mutually exclusive events ( reflection/transmission ) are detected and associated to ‘ 0 ’ or ‘ 1 ’ bit values respectively . amplification of the signal produced on the base of a reverse-biased transistor . the emitter is saturated with electrons and occasionally they will tunnel through the band gap and exit via the base . this signal is then amplified through a few more transistors and the result fed into a schmitt trigger . spontaneous parametric down-conversion leading to binary phase state selection in a degenerate optical parametric oscillator . fluctuations in vacuum energy measured through homodyne detection . . classical random properties . thermal phenomena are easier to detect . they are somewhat vulnerable to attack by lowering the temperature of the system , though most systems will stop operating at temperatures low enough to reduce noise by a factor of two ( e.g . , ~150 k ) . some of the thermal phenomena used include : thermal noise from a resistor , amplified to provide a random voltage source . avalanche noise generated from an avalanche diode , or zener breakdown noise from a reverse-biased zener diode . noise ( radio ) , detected by a radio receiver attached to a pc ( though much of it , such as lightning noise , is not properly thermal noise , but most likely a chaotic phenomenon ) . in the absence of quantum effects or thermal noise , other phenomena that tend to be random , although in ways not easily characterized by laws of physics , can be used . when several such sources are combined carefully ( as in , for example , the yarrow algorithm or fortuna csprngs ) , enough entropy can be collected for the creation of cryptographic keys and nonces , though generally at restricted rates . the advantage is that this approach needs , in principle , no special hardware . the disadvantage is that a sufficiently knowledgeable attacker can surreptitiously modify the software or its inputs , thus reducing the randomness of the output , perhaps substantially . the primary source of randomness typically used in such approaches is the precise timing of the interrupts caused by mechanical input/output devices , such as keyboards and disk drives , various system information counters , etc . this last approach must be implemented carefully and may be subject to attack if it is not . for instance , the forward-security of the generator in linux 2.6.10 kernel could be broken with 2 64 or 2 96 time complexity . . clock drift . another variable physical phenomenon that is easy to measure is clock drift . there are several ways to measure and use clock drift as a source of randomness . the intel 82802 firmware hub ( fwh ) chip included a hardware rng intel corporation intel® 810 chipset design guide , june 1999 ch . 1.3.5 , p . 1-10 . using two free running oscillators , one fast and one slow . a thermal noise source ( non-commonmode noise from two diodes ) is used to modulate the frequency of the slow oscillator , which then triggers a measurement of the fast oscillator . that output is then debiased using a von neumann type decorrelation step ( see below ) . the output rate of this device is somewhat less than 100,000 bit/s . this chip was an optional component of the 840 chipset family that supported an earlier intel bus . it is not included in modern pcs . all via c3 microprocessors have included a hardware rng on the processor chip since 2003 . instead of using thermal noise , raw bits are generated by using four freerunning oscillators which are designed to run at different rates . the output of two are xored to control the bias on a third oscillator , whose output clocks the output of the fourth oscillator to produce the raw bit . minor variations in temperature , silicon characteristics , and local electrical conditions cause continuing oscillator speed variations and thus produce the entropy of the raw bits . to further ensure randomness , there are actually two such rngs on each chip , each positioned in different environments and rotated on the silicon . the final output is a mix of these two generators . the raw output rate is tens to hundreds of megabits per second , and the whitened rate is a few megabits per second . user software can access the generated random bit stream using new non-privileged machine language instructions . a software implementation of a related idea on ordinary hardware is included in cryptolib , a cryptographic routine library . the algorithm is called truerand . most modern computers have two crystal oscillators , one for the real-time clock and one for the primary cpu clock ; truerand exploits this fact . it uses an operating system service that sets an alarm , running off the real-time clock . one subroutine sets that alarm to go off in one clock tick ( usually 1/60th of a second ) . another then enters a while loop waiting for the alarm to trigger . since the alarm will not always trigger in exactly one tick , the least significant bits of a count of loop iterations , between setting the alarm and its trigger , will vary randomly , possibly enough for some uses . truerand does n't require additional hardware , but in a multi-tasking system great care must be taken to avoid non-randomizing interference from other processes ( e.g . , in the suspension of the counting loop process as the operating system scheduler starts and stops assorted processes ) . the rdrand opcode will return values from an onboard hardware random number generator . it is present in intel ivy bridge processors and amd64 processors since 2015 . . dealing with bias . the bit-stream from such systems is prone to be biased , with either 1s or 0s predominating . there are two approaches to dealing with bias and other artifacts . the first is to design the rng to minimize bias inherent in the operation of the generator . one method to correct this feeds back the generated bit stream , filtered by a low-pass filter , to adjust the bias of the generator . by the central limit theorem , the feedback loop will tend to be well-adjusted 'almost all the time ' . ultra-high speed random number generators often use this method . even then , the numbers generated are usually somewhat biased . software whitening . a second approach to coping with bias is to reduce it after generation ( in software or hardware ) . there are several techniques for reducing bias and correlation , often called '' whitening '' algorithms , by analogy with the related problem of producing white noise from a correlated signal . john von neumann invented a simple algorithm to fix simple bias and reduce correlation . it considers two bits at a time ( non-overlapping ) , taking one of three actions : when two successive bits are equal , they are discarded ; a sequence of 1,0 becomes a 1 ; and a sequence of 0,1 becomes a zero . it thus represents a falling edge with a 1 , and a rising edge with a 0 . this eliminates simple bias , and is easy to implement as a computer program or in digital logic . this technique works no matter how the bits have been generated . it can not assure randomness in its output , however . what it can do ( with significant numbers of discarded bits ) is transform a biased random bit stream into an unbiased one . another technique for improving a near random bit stream is to xor the bit stream with the output of a high-quality cryptographically secure pseudorandom number generator such as blum blum shub or a strong stream cipher . this can improve decorrelation and digit bias at low cost ; it can be done by hardware , such as an fpga , which is faster than doing it by software . a related method which reduces bias in a near random bit stream is to take two or more uncorrelated near random bit streams , and exclusive or them together . let the probability of a bit stream producing a 0 be 1/2 & nbsp ; + & nbsp ; e , where −1/2 & nbsp ; ≤ & nbsp ; e & nbsp ; ≤ & nbsp ; 1/2 . then e is the bias of the bitstream . if two uncorrelated bit streams with bias e are exclusive-or-ed together , then the bias of the result will be 2e 2 . this may be repeated with more bit streams ( see also the piling-up lemma ) . some designs apply cryptographic hash functions such as md5 , sha-1 , or ripemd-160 or even a crc function to all or part of the bit stream , and then use the output as the random bit stream . this is attractive , partly because it is relatively fast . many physical phenomena can be used to generate bits that are highly biased , but each bit is independent from the others . a geiger counter ( with a sample time longer than the tube recovery time ) or a semi-transparent mirror photon detector both generate bit streams that are mostly '' 0 '' ( silent or transmission ) with the occasional '' 1 '' ( click or reflection ) . if each bit is independent from the others , the von neumann strategy generates one random , unbiased output bit for each of the rare '' 1 '' bits in such a highly biased bit stream . whitening techniques such as the advanced multi-level strategy ( amls ) . can extract more output bits – output bits that are just as random and unbiased – from such a highly biased bit stream . . . prng with periodically refreshed random key . other designs use what are believed to be true random bits as the key for a high quality block cipher algorithm , taking the encrypted output as the random bit stream . care must be taken in these cases to select an appropriate block mode , however . in some implementations , the prng is run for a limited number of digits , while the hardware generating device produces a new seed . using observed events . software engineers without true random number generators often try to develop them by measuring physical events available to the software . an example is measuring the time between user keystrokes , and then taking the least significant bit ( or two or three ) of the count as a random digit . a similar approach measures task-scheduling , network hits , disk-head seek times and other internal events . one microsoft design includes a very long list of such internal values , a form of cryptographically secure pseudorandom number generator . lava lamps have also been used as the physical devices to be monitored , as in the lavarand system . the method is risky when it uses computer-controlled events because a clever , malicious attacker might be able to predict a cryptographic key by controlling the external events . it is also risky because the supposed user-generated event ( e.g . , keystrokes ) can be spoofed by a sufficiently ingenious attacker , allowing control of the '' random values '' used by the cryptography . however , with sufficient care , a system can be designed that produces cryptographically secure random numbers from the sources of randomness available in a modern computer . the basic design is to maintain an '' entropy pool '' of random bits that are assumed to be unknown to an attacker . new randomness is added whenever available ( for example , when the user hits a key ) and an estimate of the number of bits in the pool that can not be known to an attacker is kept . some of the strategies in use include : when random bits are requested , return that many bits derived from the entropy pool ( by a cryptographic hash function , say ) and decrement the estimate of the number of random bits remaining in the pool . if not enough unknown bits are available , wait until enough are available . this is the top-level design of the '' /dev/random '' device in linux , written by theodore ts ' o and used in many other unix-like operating systems . it provides high-quality random numbers so long as the estimates of the input randomness are sufficiently cautious . the linux '' /dev/urandom '' device is a simple modification which disregards estimates of input randomness , and is therefore rather less likely to have high entropy as a result . maintain a stream cipher with a key and initialization vector ( iv ) obtained from an entropy pool . when enough bits of entropy have been collected , replace both key and iv with new random values and decrease the estimated entropy remaining in the pool . this is the approach taken by the yarrow library . it provides resistance against some attacks and conserves hard-to-obtain entropy . ( de ) centralized systems . a true random number generator can be a ( de ) central service . one example of a centralized system where a random number can be acquired is the randomness beacon service from the national institute of standards and technology ; another example is random.org , a service that uses atmospheric noise to generate random binary digits ( bits ) . as an example of a decentralized system , the cardano platform uses the participants of their decentralized proof-of-stake protocol to generate random numbers . . problems . it is very easy to misconstruct hardware or software devices which attempt to generate random numbers . also , most 'break ' silently , often producing decreasingly random numbers as they degrade . a physical example might be the rapidly decreasing radioactivity of the smoke detectors mentioned earlier , if this source were used directly . failure modes in such devices are plentiful and are complicated , slow , and hard to detect . methods that combine multiple sources of entropy are more robust . because many entropy sources are often quite fragile , and fail silently , statistical tests on their output should be performed continuously . many , but not all , such devices include some such tests into the software that reads the device . attacks . just as with other components of a cryptography system , a software random number generator should be designed to resist certain attacks . defending against these attacks is difficult without a hardware entropy source . estimating entropy . there are mathematical techniques for estimating the entropy of a sequence of symbols . none are so reliable that their estimates can be fully relied upon ; there are always assumptions which may be very difficult to confirm . these are useful for determining if there is enough entropy in a seed pool , for example , but they can not , in general , distinguish between a true random source and a pseudorandom generator . this problem is avoided by the conservative use of hardware entropy sources . performance test . hardware random number generators should be constantly monitored for proper operation . rfc 4086 , fips fips 140 and nist special publication 800-90b elaine barker and john kelsey , recommendation for the entropy sources used for random bit generation , nist sp 800-90b include tests which can be used for this . also see the documentation for the new zealand cryptographic software library cryptlib . since many practical designs rely on a hardware source as an input , it will be useful to at least check that the source is still operating . statistical tests can often detect failure of a noise source , such as a radio station transmitting on a channel thought to be empty , for example . noise generator output should be sampled for testing before being passed through a '' whitener . '' some whitener designs can pass statistical tests with no random input . while detecting a large deviation from perfection would be a sign that a true random noise source has become degraded , small deviations are normal and can be an indication of proper operation . correlation of bias in the inputs to a generator design with other parameters ( e.g . , internal temperature , bus voltage ) might be additionally useful as a further check . unfortunately , with currently available ( and foreseen ) tests , passing such tests is not enough to be sure the output sequences are random . a carefully chosen design , verification that the manufactured device implements that design and continuous physical security to insure against tampering may all be needed in addition to testing for high value uses .