Cache coherence

overview . in a shared memory multiprocessor system with a separate cache memory for each processor , it is possible to have many copies of shared data : one copy in the main memory and one in the local cache of each processor that requested it . when one of the copies of data is changed , the other copies must reflect that change . cache coherence is the discipline which ensures that the changes in the values of shared operands ( data ) are propagated throughout the system in a timely fashion . the following are the requirements for cache coherence : ; write propagation : changes to the data in any cache must be propagated to other copies ( of that cache line ) in the peer caches . ; transaction serialization : reads/writes to a single memory location must be seen by all processors in the same order . theoretically , coherence can be performed at the load/store granularity . however , in practice it is generally performed at the granularity of cache blocks . . definition . coherence defines the behavior of reads and writes to a single address location . one type of data occurring simultaneously in different cache memory is called cache coherence , or in some systems , global memory . in a multiprocessor system , consider that more than one processor has cached a copy of the memory location x . the following conditions are necessary to achieve cache coherence : in a read made by a processor p to a location x that follows a write by the same processor p to x , with no writes to x by another processor occurring between the write and the read instructions made by p , x must always return the value written by p . in a read made by a processor p1 to location x that follows a write by another processor p2 to x , with no other writes to x made by any processor occurring between the two accesses and with the read and write being sufficiently separated , x must always return the value written by p2 . this condition defines the concept of coherent view of memory . propagating the writes to the shared memory location ensures that all the caches have a coherent view of the memory . if processor p1 reads the old value of x , even after the write by p2 , we can say that the memory is incoherent . the above conditions satisfy the write propagation criteria required for cache coherence . however , they are not sufficient as they do not satisfy the transaction serialization condition . to illustrate this better , consider the following example : a multi-processor system consists of four processors - p1 , p2 , p3 and p4 , all containing cached copies of a shared variable s whose initial value is 0 . processor p1 changes the value of s ( in its cached copy ) to 10 following which processor p2 changes the value of s in its own cached copy to 20 . if we ensure only write propagation , then p3 and p4 will certainly see the changes made to s by p1 and p2 . however , p3 may see the change made by p1 after seeing the change made by p2 and hence return 10 on a read to s . p4 on the other hand may see changes made by p1 and p2 in the order in which they are made and hence return 20 on a read to s . the processors p3 and p4 now have an incoherent view of the memory . therefore , in order to satisfy transaction serialization , and hence achieve cache coherence , the following condition along with the previous two mentioned in this section must be met : writes to the same location must be sequenced . in other words , if location x received two different values a and b , in this order , from any two processors , the processors can never read location x as b and then read it as a . the location x must be seen with values a and b in that order . neupane , mahesh ( april 16 , 2004 ) . '' cache coherence '' ( pdf ) . archived from the original ( pdf ) on 20 june 2010 . the alternative definition of a coherent system is via the definition of sequential consistency memory model : '' the cache coherent system must appear to execute all threads â€™ loads and stores to a single memory location in a total order that respects the program order of each thread '' . thus , the only difference between the cache coherent system and sequentially consistent system is in the number of address locations the definition talks about ( single memory location for a cache coherent system , and all memory locations for a sequentially consistent system ) . another definition is : '' a multiprocessor is cache consistent if all writes to the same memory location are performed in some sequential order '' . rarely , but especially in algorithms , coherence can instead refer to the locality of reference . multiple copies of same data can exist in different cache simultaneously and if processors are allowed to update their own copies freely , an inconsistent view of memory can result . coherence mechanisms . the two most common mechanisms of ensuring coherency are snooping and directory-based , each having their own benefits and drawbacks . snooping based protocols tend to be faster , if enough bandwidth is available , since all transactions are a request/response seen by all processors . the drawback is that snooping is n't scalable . every request must be broadcast to all nodes in a system , meaning that as the system gets larger , the size of the ( logical or physical ) bus and the bandwidth it provides must grow . directories , on the other hand , tend to have longer latencies ( with a 3 hop request/forward/respond ) but use much less bandwidth since messages are point to point and not broadcast . for this reason , many of the larger systems ( > 64 processors ) use this type of cache coherence . snooping . : first introduced in 1983 , snooping is a process where the individual caches monitor address lines for accesses to memory locations that they have cached . the write-invalidate protocols and write-update protocols make use of this mechanism . : for the snooping mechanism , a snoop filter reduces the snooping traffic by maintaining a plurality of entries , each representing a cache line that may be owned by one or more nodes . when replacement of one of the entries is required , the snoop filter selects for the replacement the entry representing the cache line or lines owned by the fewest nodes , as determined from a presence vector in each of the entries . a temporal or other type of algorithm is used to refine the selection if more than one cache line is owned by the fewest nodes . rasmus ulfsnes ( june 2013 ) . '' design of a snoop filter for snoop-based cache coherency protocols '' ( pdf ) . diva-portal.org . norwegian university of science and technology . retrieved 2014-01-20 . . directory-based . : in a directory-based system , the data being shared is placed in a common directory that maintains the coherence between caches . the directory acts as a filter through which the processor must ask permission to load an entry from the primary memory to its cache . when an entry is changed , the directory either updates or invalidates the other caches with that entry . distributed shared memory systems mimic these mechanisms in an attempt to maintain consistency between blocks of memory in loosely coupled systems . . coherence protocols . coherence protocols apply cache coherence in multiprocessor systems . the intention is that two clients must never see different values for the same shared data . the protocol must implement the basic requirements for coherence . it can be tailor-made for the target system or application . protocols can also be classified as snoopy or directory-based . typically , early systems used directory-based protocols where a directory would keep a track of the data being shared and the sharers . in snoopy protocols , the transaction requests ( to read , write , or upgrade ) are sent out to all processors . all processors snoop the request and respond appropriately . write propagation in snoopy protocols can be implemented by either of the following methods : ; write-invalidate : when a write operation is observed to a location that a cache has a copy of , the cache controller invalidates its own copy of the snooped memory location , which forces a read from main memory of the new value on its next access . ; write-update : when a write operation is observed to a location that a cache has a copy of , the cache controller updates its own copy of the snooped memory location with the new data . if the protocol design states that whenever any copy of the shared data is changed , all the other copies must be '' updated '' to reflect the change , then it is a write-update protocol . if the design states that a write to a cached copy by any processor requires other processors to discard or invalidate their cached copies , then it is a write-invalidate protocol . however , scalability is one shortcoming of broadcast protocols . various models and protocols have been devised for maintaining coherence , such as msi , mesi ( aka illinois ) , mosi , moesi , mersi , mesif , write-once , synapse , berkeley , firefly and dragon protocol . in 2011 , arm ltd proposed the amba 4 ace for handling coherency in socs . see also . consistency model directory-based coherence memory barrier non-uniform memory access ( numa ) false sharing . references . further reading .