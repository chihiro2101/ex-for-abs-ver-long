Kalman filter

history . the filter is named after hungarian émigré rudolf e . kálmán , although thorvald nicolai thiele and peter swerling developed a similar algorithm earlier . richard s . bucy of the johns hopkins applied physics laboratory contributed to the theory , leading to it sometimes being called the kalman–bucy filter . stanley f . schmidt is generally credited with developing the first implementation of a kalman filter . he realized that the filter could be divided into two distinct parts , with one part for time periods between sensor outputs and another part for incorporating measurements . mohinder s . grewal and angus p . andrews it was during a visit by kálmán to the nasa ames research center that schmidt saw the applicability of kálmán 's ideas to the nonlinear problem of trajectory estimation for the project apollo leading to its incorporation in the apollo navigation computer . this kalman filter was first described and partially developed in technical papers by swerling ( 1958 ) , kalman ( 1960 ) and kalman and bucy ( 1961 ) . kalman filters have been vital in the implementation of the navigation systems of u.s . navy nuclear ballistic missile submarines , and in the guidance and navigation systems of cruise missiles such as the u.s . navy 's tomahawk missile and the u.s . air force 's agm-86 alcm . they are also used in the guidance and navigation systems of reusable launch vehicles and the attitude control and navigation systems of spacecraft which dock at the international space station . this digital filter is sometimes called the stratonovich–kalman–bucy filter because it is a special case of a more general , nonlinear filter developed somewhat earlier by the soviet mathematician ruslan stratonovich . stratonovich , r . l . ( 1959 ) . optimum nonlinear systems which bring about a separation of a signal with constant parameters from noise . radiofizika , 2:6 , pp . & nbsp ; 892–901 . stratonovich , r . l . ( 1959 ) . on the theory of optimal non-linear filtering of random functions . theory of probability and its applications , 4 , pp . & nbsp ; 223–225 . stratonovich , r . l . ( 1960 ) application of the markov processes theory to optimal filtering . radio engineering and electronic physics , 5:11 , pp . & nbsp ; 1–19 . stratonovich , r . l . ( 1960 ) . conditional markov processes . theory of probability and its applications , 5 , pp . & nbsp ; 156–178 . in fact , some of the special case linear filter 's equations appeared in these papers by stratonovich that were published before summer 1960 , when kalman met with stratonovich during a conference in moscow . . overview of the calculation . the kalman filter uses a system 's dynamic model ( e.g . , physical laws of motion ) , known control inputs to that system , and multiple sequential measurements ( such as from sensors ) to form an estimate of the system 's varying quantities ( its state ) that is better than the estimate obtained by using only one measurement alone . as such , it is a common sensor fusion and data fusion algorithm . noisy sensor data , approximations in the equations that describe the system evolution , and external factors that are not accounted for all place limits on how well it is possible to determine the system 's state . the kalman filter deals effectively with the uncertainty due to noisy sensor data and , to some extent , with random external factors . the kalman filter produces an estimate of the state of the system as an average of the system 's predicted state and of the new measurement using a weighted mean . the purpose of the weights is that values with better ( i.e . , smaller ) estimated uncertainty are '' trusted '' more . the weights are calculated from the covariance , a measure of the estimated uncertainty of the prediction of the system 's state . the result of the weighted average is a new state estimate that lies between the predicted and measured state , and has a better estimated uncertainty than either alone . this process is repeated at every time step , with the new estimate and its covariance informing the prediction used in the following iteration . this means that kalman filter works recursively and requires only the last '' best guess '' , rather than the entire history , of a system 's state to calculate a new state . the relative certainty of the measurements and current state estimate is an important consideration , and it is common to discuss the response of the filter in terms of the kalman filter 's gain . the kalman gain is the relative weight given to the measurements and current state estimate , and can be '' tuned '' to achieve a particular performance . with a high gain , the filter places more weight on the most recent measurements , and thus follows them more responsively . with a low gain , the filter follows the model predictions more closely . at the extremes , a high gain close to one will result in a more jumpy estimated trajectory , while a low gain close to zero will smooth out noise but decrease the responsiveness . when performing the actual calculations for the filter ( as discussed below ) , the state estimate and covariances are coded into matrices to handle the multiple dimensions involved in a single set of calculations . this allows for a representation of linear relationships between different state variables ( such as position , velocity , and acceleration ) in any of the transition models or covariances . example application . as an example application , consider the problem of determining the precise location of a truck . the truck can be equipped with a gps unit that provides an estimate of the position within a few meters . the gps estimate is likely to be noisy ; readings 'jump around ' rapidly , though remaining within a few meters of the real position . in addition , since the truck is expected to follow the laws of physics , its position can also be estimated by integrating its velocity over time , determined by keeping track of wheel revolutions and the angle of the steering wheel . this is a technique known as dead reckoning . typically , the dead reckoning will provide a very smooth estimate of the truck 's position , but it will drift over time as small errors accumulate . in this example , the kalman filter can be thought of as operating in two distinct phases : predict and update . in the prediction phase , the truck 's old position will be modified according to the physical laws of motion ( the dynamic or '' state transition '' model ) . not only will a new position estimate be calculated , but also a new covariance will be calculated as well . perhaps the covariance is proportional to the speed of the truck because we are more uncertain about the accuracy of the dead reckoning position estimate at high speeds but very certain about the position estimate at low speeds . next , in the update phase , a measurement of the truck 's position is taken from the gps unit . along with this measurement comes some amount of uncertainty , and its covariance relative to that of the prediction from the previous phase determines how much the new measurement will affect the updated prediction . ideally , as the dead reckoning estimates tend to drift away from the real position , the gps measurement should pull the position estimate back towards the real position but not disturb it to the point of becoming noisy and rapidly jumping . technical description and context . the kalman filter is an efficient recursive filter that estimator the internal state of a linear dynamic system from a series of noisy measurements . it is used in a wide range of engineering and econometric applications from radar and computer vision to estimation of structural macroeconomic models , and is an important topic in control theory and control systems engineering . together with the linear-quadratic regulator ( lqr ) , the kalman filter solves the linear–quadratic–gaussian control problem ( lqg ) . the kalman filter , the linear-quadratic regulator , and the linear–quadratic–gaussian controller are solutions to what arguably are the most fundamental problems in control theory . in most applications , the internal state is much larger ( more degrees of freedom ) than the few '' observable '' parameters which are measured . however , by combining a series of measurements , the kalman filter can estimate the entire internal state . in the dempster–shafer theory , each state equation or observation is considered a special case of a linear belief function and the kalman filter is a special case of combining linear belief functions on a join-tree or markov tree . additional approaches include belief filters which use bayes or evidential updates to the state equations . a wide variety of kalman filters have now been developed , from kalman 's original formulation , now called the '' simple '' kalman filter , the kalman–bucy filter , schmidt 's '' extended '' filter , the information filter , and a variety of '' square-root '' filters that were developed by bierman , thornton , and many others . perhaps the most commonly used type of very simple kalman filter is the phase-locked loop , which is now ubiquitous in radios , especially frequency modulation ( fm ) radios , television sets , satellite communications receivers , outer space communications systems , and nearly any other electronic communications equipment . underlying dynamical system model . kalman filters are based on linear dynamical systems discretized in the time domain . they are modeled on a markov chain built on linear operators perturbed by errors that may include gaussian noise . the state of the system is represented as a vector of real numbers . at each discrete time increment , a linear operator is applied to the state to generate the new state , with some noise mixed in , and optionally some information from the controls on the system if they are known . then , another linear operator mixed with more noise generates the observed outputs from the true ( '' hidden '' ) state . the kalman filter may be regarded as analogous to the hidden markov model , with the key difference that the hidden state variables take values in a continuous space as opposed to a discrete state space as in the hidden markov model . there is a strong analogy between the equations of the kalman filter and those of the hidden markov model . a review of this and other models is given in roweis and ghahramani ( 1999 ) , and hamilton ( 1994 ) , chapter 13 . hamilton , j . ( 1994 ) , time series analysis , princeton university press . chapter 13 , 'the kalman filter ' in order to use the kalman filter to estimate the internal state of a process given only a sequence of noisy observations one must model the process in accordance with the following framework . this means specifying the following matrices : f k , the state-transition model ; h k , the observation model ; q k , the covariance of the process noise ; r k , the covariance of the observation noise ; and sometimes b k , the control-input model , for each time-step , k , as described below . the kalman filter model assumes the true state at time k is evolved from the state at ( k & nbsp ; − & nbsp ; 1 ) according to : \mathbf the update equations are identical to those of the discrete-time kalman filter . variants for the recovery of sparse signals . the traditional kalman filter has also been employed for the recovery of sparse , possibly dynamic , signals from noisy observations . recent works utilize notions from the theory of compressed sensing/sampling , such as the restricted isometry property and related probabilistic recovery arguments , for sequentially estimating the sparse state in intrinsically low-dimensional systems . applications . attitude and heading reference systems autopilot battery state of charge ( soc ) estimation brain-computer interfaces chaotic signals tracking and vertex fitting of charged particles in particle detectors tracking of objects in computer vision dynamic positioning in shipping economics , in particular macroeconomics , time series analysis , and econometrics inertial guidance system nuclear medicine – single photon emission computed tomography image restoration orbit determination power system state estimation radar tracker satellite navigation systems seismology sensorless control of ac motor variable-frequency drives simultaneous localization and mapping speech enhancement visual odometry weather forecasting navigation system 3d modeling structural health monitoring human sensorimotor processing