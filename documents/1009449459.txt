Sampling (statistics)

population definition . successful statistical practice is based on focused problem definition . in sampling , this includes defining the '' population '' from which our sample is drawn . a population can be defined as including all people or items with the characteristic one wishes to understand . because there is very rarely enough time or money to gather information from everyone or everything in a population , the goal becomes finding a representative sample ( or subset ) of that population . sometimes what defines a population is obvious . for example , a manufacturer needs to decide whether a batch of material from production is of high enough quality to be released to the customer , or should be sentenced for scrap or rework due to poor quality . in this case , the batch is the population . although the population of interest often consists of physical objects , sometimes it is necessary to sample over time , space , or some combination of these dimensions . for instance , an investigation of supermarket staffing could examine checkout line length at various times , or a study on endangered penguins might aim to understand their usage of various hunting grounds over time . for the time dimension , the focus may be on periods or discrete occasions . in other cases , the examined 'population ' may be even less tangible . for example , joseph jagger studied the behaviour of roulette wheels at a casino in monte carlo , and used this to identify a biased wheel . in this case , the 'population ' jagger wanted to investigate was the overall behaviour of the wheel ( i.e . the probability distribution of its results over infinitely many trials ) , while his 'sample ' was formed from observed results from that wheel . similar considerations arise when taking repeated measurements of some physical characteristic such as the electrical conductivity of copper . this situation often arises when seeking knowledge about the cause system of which the observed population is an outcome . in such cases , sampling theory may treat the observed population as a sample from a larger 'superpopulation ' . for example , a researcher might study the success rate of a new 'quit smoking ' program on a test group of 100 patients , in order to predict the effects of the program if it were made available nationwide . here the superpopulation is '' everybody in the country , given access to this treatment '' – a group which does not yet exist , since the program is n't yet available to all . the population from which the sample is drawn may not be the same as the population about which information is desired . often there is large but not complete overlap between these two groups due to frame issues etc . ( see below ) . sometimes they may be entirely separate – for instance , one might study rats in order to get a better understanding of human health , or one might study records from people born in 2008 in order to make predictions about people born in 2009 . time spent in making the sampled population and population of concern precise is often well spent , because it raises many issues , ambiguities and questions that would otherwise have been overlooked at this stage . sampling frame . in the most straightforward case , such as the sampling of a batch of material from production ( acceptance sampling by lots ) , it would be most desirable to identify and measure every single item in the population and to include any one of them in our sample . however , in the more general case this is not usually possible or practical . there is no way to identify all rats in the set of all rats . where voting is not compulsory , there is no way to identify which people will vote at a forthcoming election ( in advance of the election ) . these imprecise populations are not amenable to sampling in any of the ways below and to which we could apply statistical theory . as a remedy , we seek a sampling frame which has the property that we can identify every single element and include any in our sample . the most straightforward type of frame is a list of elements of the population ( preferably the entire population ) with appropriate contact information . for example , in an opinion poll , possible sampling frames include an electoral register and a telephone directory . a probability sample is a sample in which every unit in the population has a chance ( greater than zero ) of being selected in the sample , and this probability can be accurately determined . the combination of these traits makes it possible to produce unbiased estimates of population totals , by weighting sampled units according to their probability of selection . example : we want to estimate the total income of adults living in a given street . we visit each household in that street , identify all adults living there , and randomly select one adult from each household . ( for example , we can allocate each person a random number , generated from a uniform distribution between 0 and 1 , and select the person with the highest number in each household ) . we then interview the selected person and find their income . people living on their own are certain to be selected , so we simply add their income to our estimate of the total . but a person living in a household of two adults has only a one-in-two chance of selection . to reflect this , when we come to such a household , we would count the selected person 's income twice towards the total . ( the person who is selected from that household can be loosely viewed as also representing the person who is n't selected . ) in the above example , not everybody has the same probability of selection ; what makes it a probability sample is the fact that each person 's probability is known . when every element in the population does have the same probability of selection , this is known as an 'equal probability of selection ' ( eps ) design . such designs are also referred to as 'self-weighting ' because all sampled units are given the same weight . probability sampling includes : simple random sample , systematic sampling , stratified sampling , probability proportional to size sampling , and cluster or multistage sampling . these various ways of probability sampling have two things in common : every element has a known nonzero probability of being sampled and involves random selection at some point . nonprobability sampling . nonprobability sampling is any sampling method where some elements of the population have no chance of selection ( these are sometimes referred to as 'out of coverage'/'undercovered ' ) , or where the probability of selection ca n't be accurately determined . it involves the selection of elements based on assumptions regarding the population of interest , which forms the criteria for selection . hence , because the selection of elements is nonrandom , nonprobability sampling does not allow the estimation of sampling errors . these conditions give rise to selection bias , placing limits on how much information a sample can provide about the population . information about the relationship between sample and population is limited , making it difficult to extrapolate from the sample to the population . example : we visit every household in a given street , and interview the first person to answer the door . in any household with more than one occupant , this is a nonprobability sample , because some people are more likely to answer the door ( e.g . an unemployed person who spends most of their time at home is more likely to answer than an employed housemate who might be at work when the interviewer calls ) and it 's not practical to calculate these probabilities . nonprobability sampling methods include convenience sampling , quota sampling and purposive sampling . in addition , nonresponse effects may turn any probability design into a nonprobability design if the characteristics of nonresponse are not well understood , since nonresponse effectively modifies each element 's probability of being sampled . sampling methods . within any of the types of frames identified above , a variety of sampling methods can be employed , individually or in combination . factors commonly influencing the choice between these designs include : nature and quality of the frame availability of auxiliary information about units on the frame accuracy requirements , and the need to measure accuracy whether detailed analysis of the sample is expected cost/operational concerns . simple random sampling . in a simple random sample ( srs ) of a given size , all subsets of a sampling frame have an equal probability of being selected . each element of the frame thus has an equal probability of selection : the frame is not subdivided or partitioned . furthermore , any given pair of elements has the same chance of selection as any other such pair ( and similarly for triples , and so on ) . this minimizes bias and simplifies analysis of results . in particular , the variance between individual results within the sample is a good indicator of variance in the overall population , which makes it relatively easy to estimate the accuracy of results . simple random sampling can be vulnerable to sampling error because the randomness of the selection may result in a sample that does n't reflect the makeup of the population . for instance , a simple random sample of ten people from a given country will on average produce five men and five women , but any given trial is likely to overrepresent one sex and underrepresent the other . systematic and stratified techniques attempt to overcome this problem by '' using information about the population '' to choose a more '' representative '' sample . also , simple random sampling can be cumbersome and tedious when sampling from a large target population . in some cases , investigators are interested in research questions specific to subgroups of the population . for example , researchers might be interested in examining whether cognitive ability as a predictor of job performance is equally applicable across racial groups . simple random sampling can not accommodate the needs of researchers in this situation , because it does not provide subsamples of the population , and other sampling strategies , such as stratified sampling , can be used instead . systematic sampling . systematic sampling ( also known as interval sampling ) relies on arranging the study population according to some ordering scheme and then selecting elements at regular intervals through that ordered list . systematic sampling involves a random start and then proceeds with the selection of every kth element from then onwards . in this case , k ( population size/sample size ) . it is important that the starting point is not automatically the first in the list , but is instead randomly chosen from within the first to the kth element in the list . a simple example would be to select every 10th name from the telephone directory ( an 'every 10th ' sample , also referred to as 'sampling with a skip of 10 ' ) . as long as the starting point is randomized , systematic sampling is a type of probability sampling . it is easy to implement and the stratification induced can make it efficient , if the variable by which the list is ordered is correlated with the variable of interest . 'every 10th ' sampling is especially useful for efficient sampling from databases . for example , suppose we wish to sample people from a long street that starts in a poor area ( house no . 1 ) and ends in an expensive district ( house no . 1000 ) . a simple random selection of addresses from this street could easily end up with too many from the high end and too few from the low end ( or vice versa ) , leading to an unrepresentative sample . selecting ( e.g . ) every 10th street number along the street ensures that the sample is spread evenly along the length of the street , representing all of these districts . ( note that if we always start at house 1 and end at 991 , the sample is slightly biased towards the low end ; by randomly selecting the start between 1 and 10 , this bias is eliminated . however , systematic sampling is especially vulnerable to periodicities in the list . if periodicity is present and the period is a multiple or factor of the interval used , the sample is especially likely to be unrepresentative of the overall population , making the scheme less accurate than simple random sampling . for example , consider a street where the odd-numbered houses are all on the north ( expensive ) side of the road , and the even-numbered houses are all on the south ( cheap ) side . under the sampling scheme given above , it is impossible to get a representative sample ; either the houses sampled will all be from the odd-numbered , expensive side , or they will all be from the even-numbered , cheap side , unless the researcher has previous knowledge of this bias and avoids it by a using a skip which ensures jumping between the two sides ( any odd-numbered skip ) . another drawback of systematic sampling is that even in scenarios where it is more accurate than srs , its theoretical properties make it difficult to quantify that accuracy . ( in the two examples of systematic sampling that are given above , much of the potential sampling error is due to variation between neighbouring houses – but because this method never selects two neighbouring houses , the sample will not give us any information on that variation . ) as described above , systematic sampling is an eps method , because all elements have the same probability of selection ( in the example given , one in ten ) . it is not 'simple random sampling ' because different subsets of the same size have different selection probabilities – e.g . the set has zero probability of selection . systematic sampling can also be adapted to a non-eps approach ; for an example , see discussion of pps samples below . stratified sampling . when the population embraces a number of distinct categories , the frame can be organized by these categories into separate '' strata . '' each stratum is then sampled as an independent sub-population , out of which individual elements can be randomly selected . the ratio of the size of this random selection ( or sample ) to the size of the population is called a sampling fraction . there are several potential benefits to stratified sampling . first , dividing the population into distinct , independent strata can enable researchers to draw inferences about specific subgroups that may be lost in a more generalized random sample . second , utilizing a stratified sampling method can lead to more efficient statistical estimates ( provided that strata are selected based upon relevance to the criterion in question , instead of availability of the samples ) . even if a stratified sampling approach does not lead to increased statistical efficiency , such a tactic will not result in less efficiency than would simple random sampling , provided that each stratum is proportional to the group 's size in the population . third , it is sometimes the case that data are more readily available for individual , pre-existing strata within a population than for the overall population ; in such cases , using a stratified sampling approach may be more convenient than aggregating data across groups ( though this may potentially be at odds with the previously noted importance of utilizing criterion-relevant strata ) . finally , since each stratum is treated as an independent population , different sampling approaches can be applied to different strata , potentially enabling researchers to use the approach best suited ( or most cost-effective ) for each identified subgroup within the population . there are , however , some potential drawbacks to using stratified sampling . first , identifying strata and implementing such an approach can increase the cost and complexity of sample selection , as well as leading to increased complexity of population estimates . second , when examining multiple criteria , stratifying variables may be related to some , but not to others , further complicating the design , and potentially reducing the utility of the strata . finally , in some cases ( such as designs with a large number of strata , or those with a specified minimum sample size per group ) , stratified sampling can potentially require a larger sample than would other methods ( although in most cases , the required sample size would be no larger than would be required for simple random sampling ) . ; a stratified sampling approach is most effective when three conditions are met : variability within strata are minimized variability between strata are maximized the variables upon which the population is stratified are strongly correlated with the desired dependent variable . ; advantages over other sampling methods focuses on important subpopulations and ignores irrelevant ones . allows use of different sampling techniques for different subpopulations . improves the accuracy/efficiency of estimation . permits greater balancing of statistical power of tests of differences between strata by sampling equal numbers from strata varying widely in size . ; disadvantages requires selection of relevant stratification variables which can be difficult . is not useful when there are no homogeneous subgroups . can be expensive to implement . ; poststratification stratification is sometimes introduced after the sampling phase in a process called '' poststratification '' . this approach is typically implemented due to a lack of prior knowledge of an appropriate stratifying variable or when the experimenter lacks the necessary information to create a stratifying variable during the sampling phase . although the method is susceptible to the pitfalls of post hoc approaches , it can provide several benefits in the right situation . implementation usually follows a simple random sample . in addition to allowing for stratification on an ancillary variable , poststratification can be used to implement weighting , which can improve the precision of a sample 's estimates . ; oversampling choice-based sampling is one of the stratified sampling strategies . in choice-based sampling , the data are stratified on the target and a sample is taken from each stratum so that the rare target class will be more represented in the sample . the model is then built on this sampling bias . the effects of the input variables on the target are often estimated with more precision with the choice-based sample even when a smaller overall sample size is taken , compared to a random sample . the results usually must be adjusted to correct for the oversampling . probability-proportional-to-size sampling . in some cases the sample designer has access to an '' auxiliary variable '' or '' size measure '' , believed to be correlated to the variable of interest , for each element in the population . these data can be used to improve accuracy in sample design . one option is to use the auxiliary variable as a basis for stratification , as discussed above . another option is probability proportional to size ( 'pps ' ) sampling , in which the selection probability for each element is set to be proportional to its size measure , up to a maximum of 1 . in a simple pps design , these selection probabilities can then be used as the basis for poisson sampling . however , this has the drawback of variable sample size , and different portions of the population may still be over- or under-represented due to chance variation in selections . systematic sampling theory can be used to create a probability proportionate to size sample . this is done by treating each count within the size variable as a single sampling unit . samples are then identified by selecting at even intervals among these counts within the size variable . this method is sometimes called pps-sequential or monetary unit sampling in the case of audits or forensic sampling . example : suppose we have six schools with populations of 150 , 180 , 200 , 220 , 260 , and & nbsp ; 490 students respectively ( total 1500 students ) , and we want to use student population as the basis for a pps sample of size three . to do this , we could allocate the first school numbers 1 & nbsp ; to & nbsp ; 150 , the second school 151 to 330 & nbsp ; ( & nbsp ; 150 & nbsp ; + & nbsp ; 180 ) , the third school 331 to 530 , and so on to the last school ( 1011 to & nbsp ; 1500 ) . we then generate a random start between 1 and 500 ( equal to & nbsp ; 1500/3 ) and count through the school populations by multiples of 500 . if our random start was 137 , we would select the schools which have been allocated numbers 137 , 637 , and & nbsp ; 1137 , i.e . the first , fourth , and sixth schools . the pps approach can improve accuracy for a given sample size by concentrating sample on large elements that have the greatest impact on population estimates . pps sampling is commonly used for surveys of businesses , where element size varies greatly and auxiliary information is often available & nbsp ; – for instance , a survey attempting to measure the number of guest-nights spent in hotels might use each hotel 's number of rooms as an auxiliary variable . in some cases , an older measurement of the variable of interest can be used as an auxiliary variable when attempting to produce more current estimates . . cluster sampling . sometimes it is more cost-effective to select respondents in groups ( 'clusters ' ) . sampling is often clustered by geography , or by time periods . ( nearly all samples are in some sense 'clustered ' in time – although this is rarely taken into account in the analysis . ) for instance , if surveying households within a city , we might choose to select 100 city blocks and then interview every household within the selected blocks . clustering can reduce travel and administrative costs . in the example above , an interviewer can make a single trip to visit several households in one block , rather than having to drive to a different block for each household . it also means that one does not need a sampling frame listing all elements in the target population . instead , clusters can be chosen from a cluster-level frame , with an element-level frame created only for the selected clusters . in the example above , the sample only requires a block-level city map for initial selections , and then a household-level map of the 100 selected blocks , rather than a household-level map of the whole city . cluster sampling ( also known as clustered sampling ) generally increases the variability of sample estimates above that of simple random sampling , depending on how the clusters differ between one another as compared to the within-cluster variation . for this reason , cluster sampling requires a larger sample than srs to achieve the same level of accuracy – but cost savings from clustering might still make this a cheaper option . cluster sampling is commonly implemented as multistage sampling . this is a complex form of cluster sampling in which two or more levels of units are embedded one in the other . the first stage consists of constructing the clusters that will be used to sample from . in the second stage , a sample of primary units is randomly selected from each cluster ( rather than using all units contained in all selected clusters ) . in following stages , in each of those selected clusters , additional samples of units are selected , and so on . all ultimate units ( individuals , for instance ) selected at the last step of this procedure are then surveyed . this technique , thus , is essentially the process of taking random subsamples of preceding random samples . multistage sampling can substantially reduce sampling costs , where the complete population list would need to be constructed ( before other sampling methods could be applied ) . by eliminating the work involved in describing clusters that are not selected , multistage sampling can reduce the large costs associated with traditional cluster sampling . however , each sample may not be a full representative of the whole population . quota sampling . in quota sampling , the population is first segmented into mutually exclusive sub-groups , just as in stratified sampling . then judgement is used to select the subjects or units from each segment based on a specified proportion . for example , an interviewer may be told to sample 200 females and 300 males between the age of 45 and 60 . it is this second step which makes the technique one of non-probability sampling . in quota sampling the selection of the sample is non-random . for example , interviewers might be tempted to interview those who look most helpful . the problem is that these samples may be biased because not everyone gets a chance of selection . this random element is its greatest weakness and quota versus probability has been a matter of controversy for several years . minimax sampling . in imbalanced datasets , where the sampling ratio does not follow the population statistics , one can resample the dataset in a conservative manner called minimax . the minimax sampling has its origin in anderson minimax ratio whose value is proved to be 0.5 : in a binary classification , the class-sample sizes should be chosen equally . this ratio can be proved to be minimax ratio only under the assumption of lda classifier with gaussian distributions . the notion of minimax sampling is recently developed for a general class of classification rules , called class-wise smart classifiers . in this case , the sampling ratio of classes is selected so that the worst case classifier error over all the possible population statistics for class prior probabilities , would be the best . . accidental sampling . accidental sampling ( sometimes known as grab , convenience or opportunity sampling ) is a type of nonprobability sampling which involves the sample being drawn from that part of the population which is close to hand . that is , a population is selected because it is readily available and convenient . it may be through meeting the person or including a person in the sample when one meets them or chosen by finding them through technological means such as the internet or through phone . the researcher using such a sample can not scientifically make generalizations about the total population from this sample because it would not be representative enough . for example , if the interviewer were to conduct such a survey at a shopping center early in the morning on a given day , the people that he/she could interview would be limited to those given there at that given time , which would not represent the views of other members of society in such an area , if the survey were to be conducted at different times of day and several times per week . this type of sampling is most useful for pilot testing . several important considerations for researchers using convenience samples include : are there controls within the research design or experiment which can serve to lessen the impact of a non-random convenience sample , thereby ensuring the results will be more representative of the population ? is there good reason to believe that a particular convenience sample would or should respond or behave differently than a random sample from the same population ? is the question being asked by the research one that can adequately be answered using a convenience sample ? in social science research , snowball sampling is a similar technique , where existing study subjects are used to recruit more subjects into the sample . some variants of snowball sampling , such as respondent driven sampling , allow calculation of selection probabilities and are probability sampling methods under certain conditions . voluntary sampling . the voluntary sampling method is a type of non-probability sampling . volunteers choose to complete a survey . volunteers may be invited through advertisements in social media . the target population for advertisements can be selected by characteristics like location , age , sex , income , occupation , education or interests using tools provided by the social medium . the advertisement may include a message about the research and link to a survey . after following the link and completing the survey the volunteer submits the data to be included in the sample population . this method can reach a global population but is limited by the campaign budget . volunteers outside the invited population may also be included in the sample . it is difficult to make generalizations from this sample because it may not represent the total population . often , volunteers have a strong interest in the main topic of the survey . line-intercept sampling . line-intercept sampling is a method of sampling elements in a region whereby an element is sampled if a chosen line segment , called a '' transect '' , intersects the element . panel sampling . panel sampling is the method of first selecting a group of participants through a random sampling method and then asking that group for ( potentially the same ) information several times over a period of time . therefore , each participant is interviewed at two or more time points ; each period of data collection is called a '' wave '' . the method was developed by sociologist paul lazarsfeld in 1938 as a means of studying political campaigns . lazarsfeld , p . , & fiske , m . ( 1938 ) . the '' panel '' as a new tool for measuring opinion . the public opinion quarterly , 2 ( 4 ) , 596–612 . this longitudinal sampling-method allows estimates of changes in the population , for example with regard to chronic illness to job stress to weekly food expenditures . panel sampling can also be used to inform researchers about within-person health changes due to age or to help explain changes in continuous dependent variables such as spousal interaction . groves , et alia . survey methodology there have been several proposed methods of analyzing panel data , including manova , growth curves , and structural equation modeling with lagged effects . snowball sampling . snowball sampling involves finding a small group of initial respondents and using them to recruit more respondents . it is particularly useful in cases where the population is hidden or difficult to enumerate . theoretical sampling . theoretical sampling occurs when samples are selected on the basis of the results of the data collected so far with a goal of developing a deeper understanding of the area or develop theories . extreme or very specific cases might be selected in order to maximize the likelihood a phenomenon will actually be observable . replacement of selected units . sampling schemes may be without replacement ( 'wor ' & nbsp ; – no element can be selected more than once in the same sample ) or with replacement ( 'wr ' & nbsp ; – an element may appear multiple times in the one sample ) . for example , if we catch fish , measure them , and immediately return them to the water before continuing with the sample , this is a wr design , because we might end up catching and measuring the same fish more than once . however , if we do not return the fish to the water or tag and release each fish after catching it , this becomes a wor design . sample size determination . formulas , tables , and power function charts are well known approaches to determine sample size . steps for using sample size tables . postulate the effect size of interest , α , and β . check sample size table cohen , 1988 select the table corresponding to the selected α locate the row corresponding to the desired power locate the column corresponding to the estimated effect size . the intersection of the column and row is the minimum sample size required . sampling and data collection . good data collection involves : following the defined sampling process keeping the data in time order noting comments and other contextual events recording non-responses . applications of sampling . sampling enables the selection of right data points from within the larger data set to estimate the characteristics of the whole population . for example , there are about 600 million tweets produced every day . it is not necessary to look at all of them to determine the topics that are discussed during the day , nor is it necessary to look at all the tweets to determine the sentiment on each of the topics . a theoretical formulation for sampling twitter data has been developed . in manufacturing different types of sensory data such as acoustics , vibration , pressure , current , voltage and controller data are available at short time intervals . to predict down-time it may not be necessary to look at all the data but a sample may be sufficient . errors in sample surveys . survey results are typically subject to some error . total errors can be classified into sampling errors and non-sampling errors . the term '' error '' here includes systematic biases as well as random errors . sampling errors and biases . sampling errors and biases are induced by the sample design . they include : selection bias : when the true selection probabilities differ from those assumed in calculating the results . sampling error : random variation in the results due to the elements in the sample being selected at random . non-sampling error . non-sampling errors are other errors which can impact final survey estimates , caused by problems in data collection , processing , or sample design . such errors may include : over-coverage : inclusion of data from outside of the population under-coverage : sampling frame does not include elements in the population . measurement error : e.g . when respondents misunderstand a question , or find it difficult to answer processing error : mistakes in data coding participation bias : failure to obtain complete data from all selected individuals after sampling , a review should be held of the exact process followed in sampling , rather than that intended , in order to study any effects that any divergences might have on subsequent analysis . a particular problem involves non-response . two major types of non-response exist : berinsky , a . j . ( 2008 ) . '' survey non-response '' . in : w . donsbach & m . w . traugott ( eds . ) , the sage handbook of public opinion research ( pp . 309–321 ) . thousand oaks , ca : sage publications . dillman , d . a . , eltinge , j . l . , groves , r . m . , & little , r . j . a . ( 2002 ) . '' survey nonresponse in design , data collection , and analysis '' . in : r . m . groves , d . a . dillman , j . l . eltinge , & r . j . a . little ( eds . ) , survey nonresponse ( pp . 3–26 ) . new york : john wiley & sons . unit nonresponse ( lack of completion of any part of the survey ) item non-response ( submission or participation in survey but failing to complete one or more components/questions of the survey ) in survey sampling , many of the individuals identified as part of the sample may be unwilling to participate , not have the time to participate ( opportunity cost ) , dillman , d.a . , smyth , j.d . , & christian , l . m . ( 2009 ) . internet , mail , and mixed-mode surveys : the tailored design method . san francisco : jossey-bass . or survey administrators may not have been able to contact them . in this case , there is a risk of differences between respondents and nonrespondents , leading to biased estimates of population parameters . this is often addressed by improving survey design , offering incentives , and conducting follow-up studies which make a repeated attempt to contact the unresponsive and to characterize their similarities and differences with the rest of the frame . vehovar , v . , batagelj , z . , manfreda , k.l . , & zaletel , m . ( 2002 ) . '' nonresponse in web surveys '' . in : r . m . groves , d . a . dillman , j . l . eltinge , & r . j . a . little ( eds . ) , survey nonresponse ( pp . 229–242 ) . new york : john wiley & sons . the effects can also be mitigated by weighting the data ( when population benchmarks are available ) or by imputing data based on answers to other questions . nonresponse is particularly a problem in internet sampling . reasons for this problem may include improperly designed surveys , over-surveying ( or survey fatigue ) , and the fact that potential participants may have multiple e-mail addresses , which they do n't use anymore or do n't check regularly . survey weights . in many situations the sample fraction may be varied by stratum and data will have to be weighted to correctly represent the population . thus for example , a simple random sample of individuals in the united kingdom might not include some in remote scottish islands who would be inordinately expensive to sample . a cheaper method would be to use a stratified sample with urban and rural strata . the rural sample could be under-represented in the sample , but weighted up appropriately in the analysis to compensate . more generally , data should usually be weighted if the sample design does not give each individual an equal chance of being selected . for instance , when households have equal selection probabilities but one person is interviewed from within each household , this gives people from large households a smaller chance of being interviewed . this can be accounted for using survey weights . similarly , households with more than one telephone line have a greater chance of being selected in a random digit dialing sample , and weights can adjust for this . weights can also serve other purposes , such as helping to correct for non-response . methods of producing random samples . random number table mathematical algorithms for pseudo-random number generators physical randomization devices such as coins , playing cards or sophisticated devices such as ernie . history . random sampling by using lots is an old idea , mentioned several times in the bible . in 1786 pierre simon laplace estimated the population of france by using a sample , along with ratio estimator . he also computed probabilistic estimates of the error . these were not expressed as modern confidence intervals but as the sample size that would be needed to achieve a particular upper bound on the sampling error with probability 1000/1001 . his estimates used bayes ' theorem with a uniform prior probability and assumed that his sample was random . alexander ivanovich chuprov introduced sample surveys to imperial russia in the 1870s . in the us the 1936 literary digest prediction of a republican win in the presidential election went badly awry , due to severe bias more than two million people responded to the study with their names obtained through magazine subscription lists and telephone directories . it was not appreciated that these lists were heavily biased towards republicans and the resulting sample , though very large , was deeply flawed . david s . moore and george p . mccabe . '' introduction to the practice of statistics '' .